---
title: "Predicting psychopathic traits in violent offenders: Executive functions and the impact of attention-deficit hyperactivity disorder and substance use disorders"
author: "Carl Delfin"
date: "28 April 2017"
output:
  html_document:
    theme: simplex
    highlight: pygments
    toc: true
    toc_depth: 3
    number_sections: true
---

# Introduction

This is an RMarkdown document containing the R code used for all statistical analysis in the study *Predicting psychopathic traits in violent offenders: Executive functions and the impact of attention-deficit hyperactivity disorder and substance use disorders*.

In the document, `this` refers to a function within R, and  [this](https://en.wikipedia.org/wiki/Hyperlink) is a link to some external website.

# Set-up

## Clear environment

```{r}
rm(list=ls())
```

## Functions

Source functions for *k*-fold cross-validation and confidence interval estimation using heteroscedasticity consistent standard errors.
```{r}
source('scripts/kfoldcv.R')
source('scripts/confintrobust.R')
```

## Load packages
```{r, message=FALSE, warning=TRUE}
library(foreign)      # 'read.spss' function
library(psych)        # required for 'describe' function in table_1.R
library(Rmisc)        # required for 'CI' function in kfoldcv.R
library(plyr)         # 'count' function
library(dplyr)        # 'group_by' function
library(ggplot2)      # pretty graphics
library(broom)        # 'tidy' function
library(relaimpo)     # relative importance estimation
library(lmtest)       # wald F test
library(sandwich)     # heteroscedasticity-consistent standard errors
library(car)          # variance inflation factors
library(cowplot)      # 'plot_grid' function
library(qvalue)       # FDR correction
library(ReporteRs)    # 'FlexTable' function
library(gdata)        # 'keep' function
```

## Prepare data

Set working directory, read data, recalcuate one variable (from milliseconds to seconds), and set seed (I use the year the analysis was conducted, in this case 2017). The `seed` function uses [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister) by default.
```{r, warning=FALSE}
setwd("/Users/delfin/Dropbox/forskning/projekt/EF-psychopathy/")

# if on Windows, uncomment and use this line instead
# setwd("C:\\Users\\Lokaladm\\Dropbox\\forskning\\projekt\\EF-psychopathy\\")

# read the data file
data = read.spss("data/data_20170317_N237.sav", to.data.frame = TRUE)

# recode variable
data$SOCMITT5 <- data$SOCMITT5/1000

# set seed
seed = 2017
```

# Descriptive overview of data

## Numerical variables

Table 1 in the article consists of an overview of numerical variables. Using `FlexTable`, a Word document with the table is created. See *table_1.R* for details.
```{r}
source("scripts/table_1.R")

# round numbers to two decimal points
table1 <- round(table1, 2)

# add rownames column (FlexTable makes using row names difficult, so this is a workaround)
table1$rownames <- c("Age", "PCL-R Facet 1", "PCL-R Facet 2", "PCL-R Facet 3", "PCL-R Facet 4",
                     "PCL-R Total Score","SOCMITT5", "SOCPS", "IEDstages", "IEDstageser", 
                     "SWMstrategy", "SWMtotaler")

# reorder columns
table1 <- table1[,c("rownames","Mean","SD","Median", "Min", "Max")]

# create FlexTable
table1 <- FlexTable(table1, header.columns=FALSE,
                    header.text.props = textProperties(font.size = 10, font.weight = "bold"),
                    body.text.props = textProperties(font.size = 10))

# add header
table1 <-  addHeaderRow(table1, value = c("", "Mean", "SD", "Median", "Min", "Max"),
                        text.properties = textBold())

# write to .docx
doc <-  docx()
doc <- addFlexTable(doc, table1)
writeDoc(doc, file = "results/table1.docx")
```

## Categorical variables

The ADHD and SUD variables are summarized in text, so output is just a .txt.
```{r}
# create a data frame
catdesc <- as.data.frame(summarise(group_by(data,SUD,ADHD),count=n()))

# capture the output of 'cat'
catdesc <- capture.output(
  cat("\nA total of", catdesc[1,3], "participants did not reach the criteria for either ADHD or SUD"),
  cat("\nA total of", plyr::count(data$ADHD)[2,2], "participants reached the criteria for ADHD"),
  cat("\nA total of", plyr::count(data$SUD)[2,2], "participants reached the criteria for SUD"),
  cat("\nA total of", catdesc[2,3], "participants reached the criteria for ADHD but not for SUD"),
  cat("\nA total of", catdesc[3,3], "participants reached the criteria for SUD but not for ADHD"),
  cat("\nA total of", catdesc[4,3], "participants reached the criteria for both ADHD and SUD"))

# save to file
write(catdesc, file = "results/categoricaldescription.txt")
```

# Regression models

We (1) want to investigate how well PCL-R scores (i.e., psychopathic traits) are predicted from a set of executive function (EF) measures and then (2) assess the impact of ADHD and SUD on these predictions. To do so, the regression models are built in two steps, with step 1 using EF predictors only and step 2 using EF + ADHD & SUD predictors. This procedure is called *hierarchical regression* in most psychology contexts, which is **not** to be confused with [multilevel modeling](https://en.wikipedia.org/wiki/Multilevel_model), sometimes also called hierarchical linear regression or hierarchical linear modeling. 

There are five outcomes (or dependent variables) and two steps, thus ten regression models in total. All models in each step are stored within a list, so that we can use `lapply` to do stuff to all models at once. The formulas in must be human readable for `lapply` to work properly, hence the pre-specification of model formulas.

## Model formulas

Model formulas are also stored in lists.
```{r}
# step 1 models
step1formulas <- list(
  Facet1 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler,
  Facet2 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler,
  Facet3 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler,
  Facet4 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler,
  TotalScore ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler)

# step 2 models
step2formulas <- list(
  Facet1 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler+ADHD+SUD,
  Facet2 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler+ADHD+SUD,
  Facet3 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler+ADHD+SUD,
  Facet4 ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler+ADHD+SUD,
  TotalScore ~ SOCMITT5+SOCPS+IEDstages+IEDstageser+SWMstrategy+SWMtotaler+ADHD+SUD)
```

## Model building

The model building process goes like this:

1.  Create lists of regression models (contained in *step1models* and *step2models*)

Then for each model:

2.  Do *k*-fold cross-validaton
3.  Calculate model *F* using `waldtest` with [heteroscedasticity consistent (HC) standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors)
4.  Calculate coefficient statistics using HC standard errors
5.  Calculate coefficient confidence intervals using HC standard errors
5.  Calculate [variance inflation factors](https://en.wikipedia.org/wiki/Variance_inflation_factor)
6.  Calculate relative importance estimation

### Build step 1 models
```{r}
step1models <- lapply(step1formulas,                                  # create list,
                      function(x, data) eval(bquote(lm(.(x),data))),  # this line evaluates formulas in
                      data=data)                                      # human readable format

step1cv <- lapply(step1models, kfoldcv, folds=5, runs=100, seed=seed) # k-fold CV
step1wald <- lapply(step1models, waldtest, test="F", vcov=vcovHC)     # HC Wald F tests
step1coefHC <- lapply(step1models, coeftest, vcov=vcovHC)             # HC t tests
step1ci <- lapply(step1models, confint.robust)                        # HC CIs
step1vif <- lapply(step1models, vif)                                  # VIFs
step1ri <- lapply(step1models, calc.relimp, rela=T)                   # relative importance
```

### Build step 2 models
```{r}
step2models <- lapply(step2formulas,                                  # same as above but for step 2
                      function(x, data) eval(bquote(lm(.(x),data))),
                      data=data)

step2cv <- lapply(step2models, kfoldcv, folds=5, runs=100, seed=seed)
step2wald <- lapply(step2models, waldtest, test="F", vcov=vcovHC)
step2coefHC <- lapply(step2models, coeftest, vcov=vcovHC)
step2ci <- lapply(step2models, confint.robust)
step2vif <- lapply(step2models, vif)
step2ri <- lapply(step2models, calc.relimp, rela=T)
```

## Model comparison

Compare all step 1 and 2 models, again with Wald *F* using HC standard errors
```{r}
waldmod <- NULL
for (i in 1:5) {
 waldmod[[i]] <- waldtest(step1models[[i]], step2models[[i]], vcov=vcovHC)
}
```

# Regression diagnostics

## Residual vs. fitted plots

The top row (panels A-E) shows to all step 1 models and the bottom row (panels F-J) shows all step 2 models.

There are definite trends visible suggesting that the homoscedasticity assumption (i.e., constant variance of the residuals) of OLS may be violated, and thus inferences may be numerically unstable (although estimates are still unbiased). Transforming makes interpretation difficult, so instead, all inferences will be based on heteroscedasticity consistent standard errors using `vcovHC` [defaulting to the recommended type, HC3](http://www.indiana.edu/~jslsoc/files_research/testing_tests/hccm/00TAS.pdf).
```{r}
source("scripts/resfitplots.R")
rfplots <- plot_grid(
  step1resfitplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 1"), 
  step1resfitplots[[2]] + ggtitle("PCL-R Affective facet\nStep 1"), 
  step1resfitplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 1"),
  step1resfitplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 1"),
  step1resfitplots[[5]] + ggtitle("PCL-R Total score\nStep 1"),
  step2resfitplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 2"),
  step2resfitplots[[2]] + ggtitle("PCL-R Affective facet\nStep 2"),
  step2resfitplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 2"),
  step2resfitplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 2"),
  step2resfitplots[[5]] + ggtitle("PCL-R Total score\nStep 2"),
  ncol=5, nrow=2, labels="AUTO")

# save figure for supplementary material
ggsave(filename="figures/rfplots.tiff", plot=rfplots, height=6, width=14, dpi=300)
```

## QQ plots

QQ plots are used to look at the distribution of residuals. Apart from PCL-R Interpersonal facet models (panels A and F; looking somewhat lognormal) the residuals seem OK. The consequences of non-normal distributions are that estimates may not be optimal, and that confidence intervals and inference tests are invalid. However, ordinary least squares regression is actually quite robust and only really long-tailed distributions cause problems, and larger sample sizes also alleviate the problem. In our case, we'll proceed as usual (although bear this is mind).
```{r}
source("scripts/qqplots.R")
qqplots <- plot_grid(
  step1qqplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 1"), 
  step1qqplots[[2]] + ggtitle("PCL-R Affective facet\nStep 1"), 
  step1qqplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 1"),
  step1qqplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 1"),
  step1qqplots[[5]] + ggtitle("PCL-R Total score\nStep 1"),
  step2qqplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 2"),
  step2qqplots[[2]] + ggtitle("PCL-R Affective facet\nStep 2"),
  step2qqplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 2"),
  step2qqplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 2"),
  step2qqplots[[5]] + ggtitle("PCL-R Total score\nStep 2"),
  ncol=5, nrow=2, labels="AUTO")

# save figure for supplementary material
ggsave(filename="figures/qqplots.tiff", plot=qqplots, height=6, width=14, dpi=300)
```

## Variance inflation factors

Collinearity is assessed by looking at variance inflation factors (VIFs). VIFs are presented in text, so we need a .txt with the output.
```{r}
# bind step 1 and step 2 lists
vifs <- rbind(step1vif, step2vif)

# print and save range of VIFs
vifs <- capture.output(cat("The VIFs range from", range(vifs)[1], "to", range(vifs)[2]))

# save to .txt
write(vifs, file = "results/vifs.txt")
```

# False discovery rate correction

Before we do FDR correction, all *p*-values must be stored in a single vector. It's important to keep track of which *p*-value corresponds to which test, otherwise things will get messy when assigning the corresponding q-value later on. **This is crucial! Make sure you understand the order or the p vector**.
```{r}
p <- NULL
for (i in 1:5) {
  p <- append(p, unname(step1coefHC[[i]][-1,4])) # six coefficient p-values 
  p <- append(p, step1wald[[i]]$`Pr(>F)`[2])     # one model F p-value
  p <- append(p, unname(step2coefHC[[i]][-1,4])) # eight coefficient p-values
  p <- append(p, step2wald[[i]]$`Pr(>F)`[2])     # one model F p-value
  p <- append(p, waldmod[[i]]$`Pr(>F)`[2])       # one model change F p-value
}                                                # thus, each model has 17 p-values
```

The p vector must have a long right tail, otherwise FDR correction will not work properly. A histogram of the p vector is saved for supplementary material.
```{r}
hist(p)
dev.copy(png,"figures/pvaluehistogram.png")
dev.off()
```

Now, using the p vector, we can do FDR correction.
```{r}
fdrcorr <- qvalue(p)  # FDR correction
q <- NULL
q <- fdrcorr$qvalues  # store q-values in q vector
```

If one were to plot the p and q vectors against their respective indices, one would see that the *q*-values are "lifted" from the bottom and "pushed" from the top, i.e., fewer low and high *q*-values than *p*-values, which is the expected result. Going a bit further, we instead plot the p and q vectors together, but with different colors. We also plot arrows pointing to the direction of change, i.e. if the *q*-value is lower or higher than the corresponding *p*-value.
```{r}
# create data frames
pp <- as.data.frame(p)
qq <- as.data.frame(q)

# add columns separating p and q
pp$var <- rep("p", length(pp))
qq$var <- rep("q", length(qq))

# rename
names(pp) <- c("val", "var")
names(qq) <- c("val", "var")

# bind
ppqq <- rbind(pp, qq)

# create dummy sequence
ppqq$seq <- rep(1:85)

# plot
ppqqplot <- ggplot(ppqq, aes(x=seq, y=val, col=var)) + 
  geom_point(alpha=0.9, size=1) +
  geom_line(arrow = arrow(length = unit(0.2,"cm"), type="open", ends="last"),
            aes(group=seq), col="gray", alpha=1, size=0.5) +
  scale_y_continuous(name="Value") +
  scale_x_continuous(name="")

# save for supplementary material
ggsave(filename="figures/ppqqplot.tiff", plot=ppqqplot, height=6, width=10, dpi=300)
```

# Preparing results

## `tidy` objects

First we create `tidy` objects for step 1 and step 2 models with HC standard errors.
```{r}
tidys1 <- lapply(step1coefHC, tidy) # tidy object for step 1 models
tidys2 <- lapply(step2coefHC, tidy) # tidy object for step 2 models
```

## Intercept and confidence intervals

The intercept is removed (the intercept was included when the regression models were estimated, but since its interpretation is fairly meaningless, it is removed from the output, allowing us to cut down on reported *p*-values). Also, HC confidence intervals for predictors are added.
```{r}
for (i in 1:length(tidys1)) {                 # tidys1
  tidys1[[i]] <- tidys1[[i]][-1,]             # remove intercept 
  tidys1[[i]]$cilow <- step1ci[[i]][-1,1]     # LL CI
  tidys1[[i]]$cihigh <- step1ci[[i]][-1,2]    # UL CI
}

for (i in 1:length(tidys2)) {                 # tidys2
  tidys2[[i]] <- tidys2[[i]][-1,]             # remove intercept
  tidys2[[i]]$cilow <- step2ci[[i]][-1,1]     # LL CI
  tidys2[[i]]$cihigh <- step2ci[[i]][-1,2]    # UL CI
}
```

## Adding coefficient *q*-values

To add the coefficient *q*-values, we'll have to go the manual way (probably could have been done programatically if I were a better coder...).

In any case, it's just a matter of selecting the correct indices of the q vector, **but make sure they are indeed the correct ones**.
```{r}
# tidys1, i.e. step 1 models
tidys1[[1]]$q.value <- q[1:6]     # six Interpersonal facet coefficient q-values
tidys1[[2]]$q.value <- q[18:23]   # six Affective facet coefficient q-values
tidys1[[3]]$q.value <- q[35:40]   # six Lifestyle facet coefficient q-values
tidys1[[4]]$q.value <- q[52:57]   # six Antisocial facet coefficient q-values
tidys1[[5]]$q.value <- q[69:74]   # six Total score coefficient q-values

# tidys2, i.e. step 2 models
tidys2[[1]]$q.value.1 <- q[8:15]  # same procedure as above,
tidys2[[2]]$q.value.1 <- q[25:32] # but now with 8 q-values,
tidys2[[3]]$q.value.1 <- q[42:49] # since there are 8 predictors in step 2
tidys2[[4]]$q.value.1 <- q[59:66]
tidys2[[5]]$q.value.1 <- q[76:83]
```

## Prepare results

### Create a list of tables

We add rows for ADHD and SUD, then merge *tidys1* and *tidys2* into *tab*.
```{r}
for (i in 1:length(tidys1)) {
  x <- rep(NA, ncol(tidys1[[i]]))
  tidys1[[i]] <- rbind(tidys1[[i]], x, x)
}

# merge using mapply and cbind
tab <- mapply(cbind, tidys1, tidys2, SIMPLIFY=F)
```

Now that we have a table (*tab* is actually of a list of data frames, but still), there's some cleaning up to do. The HC standard error is removed, since I think the HC confidence interval is more intuitive. The standard errors are in columns 3 and 11, while column 1 and 9 contain row names, so those will also be removed (we'll sort that issue out later). Also, I probably could have used some variant of `apply` for most of the following stuff instead of `for` loops, but didn't have time to figure out how.
```{r}
for (i in 1:length(tab)) {
tab[[i]] <- tab[[i]][,-c(1,9,3,11)]
}
```

It would make more sense if the confidence intervals followed the estimate, and if the *q*-value followed the *p*-value, so the columns have to be reordered (and renamed).
```{r}
for (i in 1:length(tab)) {
  # reorder
  tab[[i]] <- tab[[i]][c("estimate", "cilow","cihigh", "statistic",
                         "p.value", "q.value", "estimate.1", "cilow.1", 
                         "cihigh.1", "statistic.1", "p.value.1", "q.value.1")]
  # rename
  names(tab[[i]]) <-c("B", "95% CI LL", "95% CI UL", "t", "p", "q", 
                      "B", "95% CI LL", "95% CI UL", "t", "p", "q")
}
```

Since the *term* columns that contained predictor names were removed earlier, row names must be specified. Also, it's necessary to make room for some model statistics. A bunch of empty rows are inserted along with proper row names.
```{r}
for (i in 1:length(tab)) {
  # create empty row
  x <- rep(NA, ncol(tab[[i]]))
  
  # bind
  tab[[i]] <- rbind(tab[[i]], x, x, x, x, x, x, x, x, x, x)
  
  # add row names (perhaps redudant, see later sections with FlexTable)
  row.names(tab[[i]]) <- c("SOCMITT5", "SOCPS", "IEDstages",
                           "IEDstageser", "SWMstrategy", "SWMtotaler",
                           "ADHD", "SUD","F", "Fp", "Fq",
                           "CV R2", "CI CV R2 LL", "CI CV R2 UL",
                           "Delta F", "Delta Fp", "Delta Fq", "Delta CV R2")
}
```

### Model statistics

Now for model statistics, all of which are stored in a bunch of lists what were created earlier using `lapply`. We must put the model statistics somewhere, so why not in the *B* column, which is at indices [,1] (step 1) and [,7] (step 2). A separate row is created for the *F* test *p*-values.
```{r}
for (i in 1:length(tab)) {
  # step 1
  tab[[i]][9,1] <- step1wald[[i]]$F[2]          # model F value
  tab[[i]][10,1] <- step1wald[[i]]$`Pr(>F)`[2]  # model F p-value
  tab[[i]][12,1] <- step1cv[[i]][4]             # CV R2
  tab[[i]][13,1] <- step1cv[[i]][5]             # CI CV R2 LL
  tab[[i]][14,1] <- step1cv[[i]][3]             # CI CV R2 UL
  
  # step 2
  tab[[i]][9,7] <- step2wald[[i]]$F[2]          # model F value
  tab[[i]][10,7] <- step2wald[[i]]$`Pr(>F)`[2]  # model F p-value
  tab[[i]][12,7] <- step2cv[[i]][4]             # CV R2
  tab[[i]][13,7] <- step2cv[[i]][5]             # CI CV R2 LL
  tab[[i]][14,7] <- step2cv[[i]][3]             # CI CV R2 UL
  
  # model comparison
  tab[[i]][18,7] <- step2cv[[i]][3] - step1cv[[i]][3] # CV R2 change
  tab[[i]][15,7] <- waldmod[[i]]$F[2]           # model change F
  tab[[i]][16,7] <- waldmod[[i]]$`Pr(>F)`[2]    # model change F p-value
}
```

### Adding *q*-values

Again, *q*-values are added manually. **Be careful, this is where you are most likely to mess up**.
```{r}
# model 1
tab[[1]][11,1] <- q[7]        # step 1 model 1 F q-value
tab[[1]][11,7] <- q[16]       # step 2 model 1 F q-value
tab[[1]][17,7] <- q[17]       # model 1 comparison q-value

# model 2
tab[[2]][11,1] <- q[24]       # step 1 model 2 F q-value
tab[[2]][11,7] <- q[33]       # step 2 model 2 F q-value
tab[[2]][17,7] <- q[34]       # model 2 comparison q-value

# model 3
tab[[3]][11,1] <- q[41]       # step 1 model 3 F q-value
tab[[3]][11,7] <- q[50]       # step 2 model 3 F q-value
tab[[3]][17,7] <- q[51]       # model 3 comparison q-value

# model 4
tab[[4]][11,1] <- q[58]       # step 1 model 4 F q-value
tab[[4]][11,7] <- q[67]       # step 2 model 4 F q-value
tab[[4]][17,7] <- q[68]       # model 4 comparison q-value

# model 5
tab[[5]][11,1] <- q[75]       # step 1 model 5 F q-value
tab[[5]][11,7] <- q[84]       # step 2 model 5 F q-value
tab[[5]][17,7] <- q[85]       # model 5 comparison q-value
```

# Final results

## Regression models

`FlexTable` is used to create Word ready tables. It took forever to find a decent way to export everything to Word, and I don't particularly like Word, but since the publishing process is what it is...

There's still some tinkering that needs to be done manually in Word, such as removing NAs, page orientation, and other cosmetics. The main point is, you don't have to type in a single number by yourself.
```{r}
# create empty list
flextable <- NULL

for (i in 1:length(tab)) {
  # round numbers to 3 decimal points
  tab[[i]] <- round(tab[[i]], 3)
  
  # FlexTable won't allow to use rownames, so we need to create 'fake' rownames in the form of a column
  tab[[i]]$rownames <- c("SOCMITT5", "SOCPS", "IEDstages", "IEDstageser", "SWMstrategy",
                         "SWMtotaler", "ADHD", "SUD", "F", "Fp", "Fq", "CV R2", "CI CV R2 LL",
                         "CI CV R2 UL", "Delta F", "Delta Fp", "Delta Fq", "Delta CV R2")
  
  # reorder columns so that 'rownames' is first
  col_idx <- grep("rownames", names(tab[[i]]))
  tab[[i]] <- tab[[i]][, c(col_idx, (1:ncol(tab[[i]]))[-col_idx])]
  
  # create FlexTable
  flextable[[i]] = FlexTable(tab[[i]], header.columns=FALSE,
                             header.text.props = textProperties(font.size = 10,
                                                                font.weight = "bold"),
                             body.text.props = textProperties(font.size = 10))
  
  # add headers, level 1
  flextable[[i]] = addHeaderRow(flextable[[i]], text.properties = textBold(),
                         value = c("", "Step 1", "Step 2"), colspan = c(1,6,6))
  
  flextable[[i]] = addHeaderRow(flextable[[i]], value = c("", "B", "95% LL", "95% UL", "t", "p", "q",
                                                              "B", "95% LL", "95% UL", "t", "p", "q"),
  text.properties = textBold())
  
  # align columns (somewhat) correctly
  flextable[[i]][] = parCenter()
  flextable[[i]][, 1] <- parProperties(text.align = "left")
}
```

All regression model results are written to five separate Word documents. Could probaly loop this, but didn't have time to figure out how in a decent way.
```{r}
doc <-  docx()
doc <- addFlexTable(doc, flextable[[1]])
writeDoc(doc, file = "results/Facet1.docx")

doc <-  docx()
doc <- addFlexTable(doc, flextable[[2]])
writeDoc(doc, file = "results/Facet2.docx")

doc <-  docx()
doc <- addFlexTable(doc, flextable[[3]])
writeDoc(doc, file = "results/Facet3.docx")

doc <-  docx()
doc <- addFlexTable(doc, flextable[[4]])
writeDoc(doc, file = "results/Facet4.docx")

doc <-  docx()
doc <- addFlexTable(doc, flextable[[5]])
writeDoc(doc, file = "results/TotalScore.docx")
```

## Relative importance estimation

The relative importance esimations are plotted and saved in a .tiff image. See *relaimpo.R* for details.
```{r}
source("scripts/relaimpo.R")

riplot <- plot_grid(
  step1riplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 1"), 
  step1riplots[[2]] + ggtitle("PCL-R Affective facet\nStep 1"), 
  step1riplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 1"),
  step1riplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 1"),
  step1riplots[[5]] + ggtitle("PCL-R Total score\nStep 1"),
  step2riplots[[1]] + ggtitle("PCL-R Interpersonal facet\nStep 2"),
  step2riplots[[2]] + ggtitle("PCL-R Affective facet\nStep 2"),
  step2riplots[[3]] + ggtitle("PCL-R Lifestyle facet\nStep 2"),
  step2riplots[[4]] + ggtitle("PCL-R Antisocial facet\nStep 2"),
  step2riplots[[5]] + ggtitle("PCL-R Total score\nStep 2"),
  ncol=5, nrow=2, labels="AUTO")

# save for publication
ggsave(filename="figures/riplot.tiff", plot=riplot, height=8, width=14, dpi=300)

```

# Session info

Write a text file with the session info.
```{r}
sessInfo <- capture.output(sessionInfo())
write(sessInfo, file = "sessioninfo.txt")
```

## Clean environment

Remove everything but the original data frame. Not really necessary but I get anxious when the global environment is messy.
```{r}
keep(data, sure=TRUE)
```