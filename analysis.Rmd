---
title: "Psychopathy and executive functions: The impact of attention deficit hyperactivity disorder and substance use disorders"
author: "Carl Delfin"
date: "4 July 2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

# Introduction

This is an RMarkdown document containing the R code used for all statistical analysis in the study *Psychopathic traits and executive functions*.

In the document, `this` refers to a function within R, and  [this](https://en.wikipedia.org/wiki/Hyperlink) is a link to some external website.

# Set-up

## Clear environment

```{r}
rm(list=ls())
```

## Load packages

```{r, message=FALSE, warning=TRUE}
library(doMC)         # 'registerDoMC' function
library(foreign)      # 'read.spss' function
library(psych)        # required for 'describe' function in table_1.R
library(Rmisc)        # required for 'CI' function in kfoldcv.R
library(plyr)         # 'count' function
library(dplyr)        # 'group_by' function
library(ggplot2)      # pretty graphics
library(broom)        # 'tidy' function
library(relaimpo)     # relative importance estimation
library(lmtest)       # wald F test
library(caret)        # cross validation
library(sandwich)     # heteroscedasticity-consistent standard errors
library(car)          # variance inflation factors
library(cowplot)      # 'plot_grid' function
library(ReporteRs)    # 'FlexTable' function
library(gdata)        # 'keep' function
```

## Prepare parallel processing

```{r}
registerDoMC(cores = 2)
```

## Prepare data

Read data, recalcuate one variable (from milliseconds to seconds), and set seed (I use the year the analysis was conducted, in this case 2017). The `seed` function uses [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister) by default.

```{r, warning=FALSE}
# read the data file
data = read.spss("data/data_20171031.sav", to.data.frame = TRUE)

data$SOCMITT5 <- data$SOCMITT5 / 1000

# set seed
seed <- 2017
```

# Data preparation

## Select predictors

Define the outcome variable and which predictors to use. The names must, obviously, match variable names in the data frame.

```{r}
# other variables (age)
otherList <- "age"

# outcome
outcomeVariables <- c("totalscore", "facet1", "facet2", "facet3", "facet4")

# EF predictors
predictorList <- c("SOCMITT5","SOCPS","IEDstages", "IEDtotaler", "SWMstrategy", "SWMtotaler", "SSTSSRT", "SSTSSD50")
```

### Subset data

Subset the data to remove unecessary variables.

```{r}
# select only columns that match the variable names in our lists
idx <- match(c(otherList, outcomeVariables, predictorList), names(data))

# subset
data <- data[, idx] 

# remove idx from environment
remove(idx)
```

## Missing data

Look for missing data in the list of predictors and note how many rows (if any) contain missing values. Save that in a text file.

```{r}
# look for NAs in the predictor variables
missing <- describe(data[c(otherList, predictorList, outcomeVariables)])
missingNames <- row.names(missing)
tempMissing <- NULL

# loop through list of predictor variables and save to temporary vector
for (i in 1:length(missingNames)) {
  tempMissing <- append(tempMissing,
                        paste("There is/are",
                              nrow(data)-missing[i,2], 
                              "row/s missing in the", 
                              missingNames[i],
                              "variable"))
}

# capture output
results_missing <- capture.output(tempMissing)

# save output file to to .txt
write(results_missing, file = "results/results_missing.txt")

# remove from environment
remove(i, missing, missingNames, tempMissing, results_missing)
```

## Drop missing data

Drop missing rows

```{r}
data <- na.omit(data)
```

## Data preparation




Sixteen subjects failed to achieve convergence, either through too high (≤60%) or too low (≤40%) levels of successful inhibition. These staircase failures may arise through strategic slowing of the go reaction time, or through inconsistent performance or excessive distraction. They invalidate an assumption of the horse race model that Go-and stop-related processes are independent [11]. Thus, the final group for analysis was a total of 141 participants (94 females, 47 males).


## Functions

Source function for confidence interval estimation using heteroscedasticity consistent standard errors.

```{r}
source('scripts/confintrobust.R')
```

# Descriptive overview of data

## Numerical variables

Table 1 in the manuscript consists of an overview of numerical variables. Using `FlexTable`, a Word document with the table is created. See *table_1.R* for details.

```{r}
# describe data
table1 <- data.frame(describe(data))

# remove columns we don't want, round to two decimal points
table1 <- round(table1[, c(3:4, 8:9)], 2)

# create flextable
table1 <- FlexTable(table1,
                    header.text.props = textProperties(font.size = 10),
                    body.text.props = textProperties(font.size = 10),
                    add.rownames = TRUE)

## write to .docx
doc <- docx()
doc <- addFlexTable(doc, table1)
writeDoc(doc, file = "results/table1.docx")

# keep workspace clean
remove(doc, table1)
```

# Regression models

## Model formulas

Model formulas are also stored in lists.

```{r}
formulas <- as.list(NULL)

for (i in 1:length(outcomeVariables)) {
  formulas[[i]] <- paste(outcomeVariables[[i]], paste(predictorList, collapse = "+"), sep = "~")
}
```

Model building

For each model:

2.  Do *k*-fold cross-validaton
3.  Calculate model *F* using `waldtest` with [heteroscedasticity consistent (HC) standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors)
4.  Calculate coefficient statistics using HC standard errors
5.  Calculate coefficient confidence intervals using HC standard errors
5.  Calculate [variance inflation factors](https://en.wikipedia.org/wiki/Variance_inflation_factor)
6.  Calculate relative importance estimation

### Build step 1 models


```{r}
# estimate linear models
modelList <- lapply(formulas, function(x, data) eval(bquote(lm(.(x), data))), data = data)

# lapply through all models
modelWald <- lapply(modelList, waldtest, test = "F", vcov = vcovHC)
modelHC   <- lapply(modelList, coeftest, vcov = vcovHC)
modelCI   <- lapply(modelList, confint.robust)
modelVIF  <- lapply(modelList, vif)
modelRI   <- lapply(modelList, calc.relimp, type = "lmg", rela = FALSE)
modelCV   <- NULL

# specify repeated 10-fold CV repeated 100 times
control = trainControl(method = "repeatedcv", number = 10, repeats = 10)

# loop CV through all outcome variables 
for (i in 1:length(formulas)) {
  modelCV[[i]] <- train(as.formula(formulas[[i]]), data = data, method = "lm", trControl = control)
}

remove(formulas, control, i)
```

## Table 2

```{r}
source("scripts/table2.R")
  
# save table in Word doc
doc <- docx()
doc <- addFlexTable(doc, table2)
writeDoc(doc, file = "results/table2.docx")
remove(doc, table2, modelHC, modelCI)
```

## Model statistics

```{r}
source("scripts/regressionsummary.R")

# write to .txt
lapply(regressionsummary, write, "results/results.txt", append = TRUE)

# remove from environment
#remove(regressionsummary, modelWald, modelCV)
```

# Relative importance estimation

The relative importance esimations are plotted and saved in a .tiff image. See *relaimpo.R* for details.

```{r}
source("scripts/relaimpo.R")

riplot <- plot_grid(
  riplots[[1]] + ggtitle("PCL-R Interpersonal facet"), 
  riplots[[2]] + ggtitle("PCL-R Affective facet"), 
  riplots[[3]] + ggtitle("PCL-R Lifestyle facet"),
  riplots[[4]] + ggtitle("PCL-R Antisocial facet"),
  riplots[[5]] + ggtitle("PCL-R Total score"),
  ncol = 5, nrow = 1, labels = "AUTO")

# save for publication (in PDF)
ggsave(filename = "figures/riplot.pdf",
       plot = riplot,
       height = 8,
       width = 14,
       dpi = 300)

remove(modelRI, riplot, riplots)
```

# Regression diagnostics

## Residual vs. fitted plots

The top row (panels A-E) shows to all step 1 models and the bottom row (panels F-J) shows all step 2 models.

There are definite trends visible suggesting that the homoscedasticity assumption (i.e., constant variance of the residuals) of OLS may be violated, and thus inferences may be numerically unstable (although estimates are still unbiased). Transforming makes interpretation difficult, so instead, all inferences will be based on heteroscedasticity consistent standard errors using `vcovHC` [defaulting to the recommended type, HC3](http://www.indiana.edu/~jslsoc/files_research/testing_tests/hccm/00TAS.pdf).

```{r}
source("scripts/resfitplots.R")
rfplots <- plot_grid(
  resfitPlots[[1]] + ggtitle("PCL-R Interpersonal facet"), 
  resfitPlots[[2]] + ggtitle("PCL-R Affective facet"), 
  resfitPlots[[3]] + ggtitle("PCL-R Lifestyle facet"),
  resfitPlots[[4]] + ggtitle("PCL-R Antisocial facet"),
  resfitPlots[[5]] + ggtitle("PCL-R Total score"),
  ncol = 5, nrow = 1, labels = "AUTO")

# save figure for supplementary material
ggsave(filename = "figures/rfplots.tiff",
       plot = rfplots,
       height = 3,
       width = 14,
       dpi = 300)

remove(rfplot, resfitplots, rfplots)
```

## QQ plots

QQ plots are used to look at the distribution of residuals. Apart from PCL-R Interpersonal facet models (panels A and F; looking somewhat lognormal) the residuals seem OK. The consequences of non-normal distributions are that estimates may not be optimal, and that confidence intervals and inference tests are invalid. However, ordinary least squares regression is actually quite robust and only really long-tailed distributions cause problems, and larger sample sizes also alleviate the problem. In our case, we'll proceed as usual (although bear this is mind).

```{r}
source("scripts/qqplots.R")
qqplots <- plot_grid(
  qqPlots[[1]] + ggtitle("PCL-R Interpersonal facet"), 
  qqPlots[[2]] + ggtitle("PCL-R Affective facet"), 
  qqPlots[[3]] + ggtitle("PCL-R Lifestyle facet"),
  qqPlots[[4]] + ggtitle("PCL-R Antisocial facet"),
  qqPlots[[5]] + ggtitle("PCL-R Total score"),
  ncol = 5, nrow = 1, labels = "AUTO")

# save figure for supplementary material
ggsave(filename = "figures/qqplots.tiff",
       plot = qqplots,
       height = 3,
       width = 14,
       dpi = 300)

remove(qqPlots, qqplots)
```

## Variance inflation factors

Collinearity is assessed by looking at variance inflation factors (VIFs). VIFs are presented in text, so we only want a .txt with the output.
```{r}
# print and save range of VIFs
vifs <- capture.output(cat("The VIFs range from", range(modelVIF)[1], "to", range(modelVIF)[2]))

# save to .txt
write(vifs, file = "results/vifs.txt")

remove(modelVIF)
```

# Session info

A text file with the session info.

```{r}
sessInfo <- capture.output(sessionInfo())
write(sessInfo, file = "sessioninfo.txt")
```
